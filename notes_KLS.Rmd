---
title: "Notes on Building Tidy Tools"
author: "Kelly Sovacool"
date: "27-28 Jan. 2020"
output:
  html_document:
    toc: true
    toc_float: true
---
```{r render, eval=FALSE, echo=FALSE}
rmarkdown::render('notes_KLS.Rmd', output_file="docs/index.html")
```

Taught by Charlotte & Hadley Wickham at `rstudio::conf(2020)`.

- Repo with workshop materials: [https://github.com/rstudio-conf-2020/build-tidy-tools](https://github.com/rstudio-conf-2020/build-tidy-tools)
- [RStudio Community Thread for this workshop](https://community.rstudio.com/t/building-tidy-tools-workshop-rstudio-conf-2020/49091)
- 2nd edition of Hadley's [R Packages book](https://r-pkgs.org/index.html)
- [Package Development category in RStudio Community](https://community.rstudio.com/c/package-development)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=FALSE, error=TRUE)
```

## Libraries & Packages

```{r}
.Library
.libPaths()
```
```{r before_lib}
data.frame(env=search(), path=searchpaths())
```
```{r after_lib}
library(dplyr)
data.frame(env=search(), path=searchpaths())
```

### R setup 

Stuff to make your life easier

#### Open .Rprofile
```{r}
usethis::edit_r_profile()
```

#### Require devtools in your .Rprofile
```{r}
usethis::use_devtools()
usethis::use_partial_warnings()
```

#### Tell usethis about yourself

In your .Rprofile:

```{r who}
options(
  usethis.full_name = "Jane Doe",
  usethis.protocol  = "ssh",
  usethis.description = list(
    `Authors@R` = 'person("Jane", "Doe", email = "jane@example.com", role = c("aut", "cre"), 
    comment = c(ORCID = "YOUR-ORCID-ID"))',
    Version = "0.0.0.9000"
  )
)
```

See [`usethis` setup docs](https://usethis.r-lib.org/articles/articles/usethis-setup.html)

#### Restart R completely fresh with an empty environment OFTEN

Options in global settings:
- Don't Restore `.RData` at startup
- Don't save your workspace on exit

Better for reproducibility. 
[Also prevents fires!](https://twitter.com/hadleywickham/status/940021008764846080)

#### My .Rprofile now looks like this:

```{r Rprofile}
if (interactive()) {
    suppressMessages(require(devtools))
    suppressMessages(require(testthat))
}
options(
    warnPartialMatchArgs = TRUE,
    warnPartialMatchDollar = TRUE,
    warnPartialMatchAttr = TRUE
)
options(
    usethis.full_name = "Kelly L. Sovacool",
    usethis.protocol  = "ssh",
    usethis.description = list(
        `Authors@R` = 'person("Kelly", "Sovacool", email = "sovacool@umich.edu", role = c("aut", "cre"),
    comment = c(ORCID = "0000-0003-3283-829X"))',
        Version = "0.0.0.9000"
    )
)
```

#### sitrep functions

##### project sitrep
```{r}
usethis::proj_sitrep()
```

##### Add `.RData` & `.DS_Store` to `.gitignore`
```{r}
usethis::git_vaccinate() 
```

##### git sitrep
```{r}
usethis::git_sitrep()
```

## The Whole Game

What bulding a package looks like from start to finish

R Packages chapter: ["The Whole Game"](https://r-pkgs.org/whole-game.html)

### Create a new, empty package
```{r create_package}
usethis::create_package("~/Desktop/foofactors")
```

This opened the `foofactors` project in a new R session (switch there now).

### Make it a git repo 
```{r git_init}
usethis::use_git()
```

Let's create a new function called `fbind`.

### Create a new R file 
```{r}
usethis::use_r("fbind")
```

In `R/fbind.R`:
```{r}
fbind <- function(a, b) {
  factor(c(as.character(a), as.character(b)))
}
```
### Load the functions in the package

(not quite like installing the package)
```{r load}
devtools::load_all()
```

Keyboard shortcut: `Cmd + Shift + L`

### devtools::check() is like R CMD CHECK

Checks that the package follows all of the proper conventions.
```{r check}
devtools::check()
```

If you have 0 warnings, 0 errors, and 0 notes, everything is great!
But that's not likely to happen the first time you run `check()`.

### Document your function

Rstudio helper: `Code > Insert roxygen skeleton`

#### Then build the documentation

```{r document}
devtools::document()
```

#### Let's add a license too

```{r license}
usethis::use_mit_license()
```

`LICENSE.md` is for GitHub, `LICENSE` (no extension) is for CRAN.

Let's `check` again. 
```{r check_again}
devtools::check()
```

If everything worked, we're ready to install the package.

### Install the package as if it were on CRAN or GitHub

```{r install}
devtools::install()
```

Now you can use library!
```{r library}
library(foofactors)
```

View the documentation in the Help window just like usual:
```{r help}
?fbind
```

### Workflow Overview

While developing the package:

1. write/modify code
1. run `devtools::load_all()` to mess around with the changes you made
1. repeat

While using your package:

1. run `devtools::install(path/to/pkg)`
1. load it with `library(pkgname)`
1. use it in your analysis

## Unit Testing

Why? Automate!

Example: writing functions for inserting columns into dataframes.

```{r}
usethis::use_r("insert_into")
```

in `R/insert_into.R`:
```{r insert_into}
insert_into <- function(x, y, where = 1) {
    if (where == 1) { # first col
        cbind(y, x)
    } else if (where > ncol(x)) { # last col
        cbind(x, y)
    } else {
        lhs <- 1:(where - 1)
        cbind(x[lhs], y, x[-lhs])
    }
}
```

Manually sourcing your code and running simple test cases is tedious.

Let's write unit tests instead!

### Setup testing infrastructure

```{r use_test}
usethis::use_test("insert_into.R")
```

It created a file `tests/testthat/test-insert_into.R` with some boilerplate code to modify:
```{r}
test_that("multiplication works", {
  expect_equal(2 * 2, 4)
})
```
(You should replace this with a test that's actually useful for your code.)

Every file in `R/` should have a corresponding testfile in `tests/testthat/`.

Now whenever you run `devtools::check()`, it will also run all the unit tests.

```{r}
devtools::check()
```

#### Now let's write a useful test

in `tests/testthat/test-insert_into.R`:
```{r}
test_that("can add column at any position", {
    df1 <- data.frame(a = 3, b = 4, c = 5)
    df2 <- data.frame(X = 1, Y = 2)
    at_pos <- function(i) {
        insert_into(df1, df2, where = i)
    }

    expect_named(at_pos(1), c("X", "Y", "a", "b", "c"))
    expect_named(at_pos(2), c("a", "X", "Y", "b", "c"))
    expect_named(at_pos(3), c("a", "b", "X", "Y", "c"))
})
```

### Run the test

#### Test just one file
```{r test_file}
# with no argument, it'll assume you want to test that file you currently have open
devtools::test_file("R/insert_into.R")
```

#### Test everything without running the other checks

```{r}
devtools::test()
```
Keyboard shortcut: `Cmd + Shift + T`

### Test coverage

How well are we testing the codebase?

#### Test the coverage of a source file
```{r}
devtools::test_coverage_file("R/insert_into.R")
```

```{r}
devtools::test_coverage() 
```

#### Report test coverage with Travis CI

Have to use [Travis CI](https://travis-ci.org) for this to work (that's beyond the scope of this workshop).
```{r}
usethis::use_travis()
usethis::use_coverage()
```

Coverage builds confidence that your code does what it's supposed to do and 
guides contributors on what parts of the code need new test cases.

### Test-Driven Development 

TDD: Write the tests, then write the code.

#### Write tests for the `add_col()` function

```{r}
usethis::use_test("add_col")
```

tests in `tests/testthat/test-add_col.R`:
```{r}
test_that("where controls position", {
 df <- data.frame(x = 1)
 expect_equal(
 add_col(df, "y", 2, where = 1),
 data.frame(y = 2, x = 1)
 )
 expect_equal(
 add_col(df, "y", 2, where = 2),
 data.frame(x = 1, y = 2)
 )
}) 
```

We haven't written the function yet, so right now it fails:
```{r}
devtools::test()
```

#### Now implement `add_col()`

```{r}
usethis::use_r("add_col")
```

First attempt implentation:
```{r}
add_col <- function(x, name, value, where) {
    df2 <- data.frame(name=value)
    insert_into(x, df2, where=where)
}
```

#### Run the tests 

`Cmd + Shift + T` or `devtools::test()`

Doesn't work...

#### Modify the code

Second attempt:
```{r}
add_col <- function(x, name, value, where) {
    df2 <- data.frame(x=value)
    names(df2) <- name
    insert_into(x, df2, where=where)
}
```

#### Run the tests again
```{r}
devtools::test()
```

It works!

### What about bad inputs?

Throw errors; fail fast.

_**The hardest part about testing is writing the tests.**_

## Document and share

### Document with `roxygen2`

- Write the documentation alongside the code. 
  - `roxygen` comments start with `#'`.
  - There are special tags e.g. `@param` and `@examples`.
- `roxygen2` will parse the comments and turn them into `.Rd` files. (It's a weird format that's kinda like LaTeX but not really. Editing them manually is not recommended.)
- `R` then renders them into HTML so they look pretty in the Help pane.

See more in the [`R Packages man chapter`](https://r-pkgs.org/man.html).

#### Render documentation

`devtools::document()` or `Cmd + Shift + D`

#### Practice

**Now switching to the `fordogs` package.**

1. Fix the typos in the `fbind` function.
1. Render the documentation: `devtools::document()`.
1. View the new doc: `?fbind`.


Not every function in your package has to be available for users.
For ones that are user-facing, include the `@export` tag.

More practice: document the `fdist` function in `fordogs`.

### Vignettes

While `roxygen` comments document the individual components of the package,
vignettes are for longer prose descriptions of how to use the package overall.

```{r}
usethis::use_vignette("how-to")
```

#### README

A brief introduction; the bare minimum that someone needs to know when they come across your package. Also a nice landing page on GitHub.

```{r}
usethis::use_readme_rmd()
```

#### News

To document user-facing changes (e.g. to the API).

```{r}
usethis::use_news_md()
```

#### Turn the docs into a website with pkgdown

```{r}
usethis::use_pkgdown()
usethis::use_pkgdown_travis()
```

### Sharing

If your package passes `devtools::check()` and you put it in a public repo on GitHub, anyone else can download & install it with `devtools::install_github()`.
That's pretty cool!

To avoid frustration, run `devtools::check()` early & often. 
Your package must pass in order to submit to CRAN.

#### CRAN submission

```{r}
usethis::use_release_issue()
devtools::release()
```

Communicate with CRAN maintainers in `cran-comments.md`.
```{r}
usethis::use_cran_comments()
```

## Dependencies

How to use code from other packages,
when to use code from other packages,
and when not to use code from other packages.

### Motivation

While the code of these functions is similar,
it's the **environment** that's different.
```{r, eval=TRUE}
?sd
x <- 1:10
sd(x)
# 3.02765

var <- function(x) 100
sd(x)
# 3.02765

my_sd <- function(x) sqrt(var(x))
my_sd(x)
# 10
```

### Warm-ups

### Lexical scoping

If R can't find the variable in the current environment, 
it goes up a level until it can.

### Environments
- What is an environment?
  - collection.
  - mapping from names to objects.
  - hierarchy - every environment has a parent.
  - data structure that powers scoping.
  - can use environments as dictionaries/hashmaps.
- How is an environment different from a list?
  - environments can't really have classes (actually they can put that's not a good idea).
  - environments have parents.
  - environments are unordered.
  - overall, environments are really weird.
  - environments never get copied.
- How can you see the contents of an environment?
  - `rlang::env_print(e)`
  - if you got rid of environments (+ a few other smaller things), you'd basically end up with Python. (Which isn't bad, just not R.)

```{r env_vs_list, eval=TRUE}
library(rlang)
## env
e <- env()
e$a <- 1
e$a
#e[[1]] # doesn't work; unordered
lobstr::obj_addr(e)
e$e <- e  
e$e
lobstr::obj_addr(e)  # e didn't get overwritten

## list
l = list(a=1)
l$l <- l  # original list got overwritten
l
```

```{r, eval=TRUE}
e
str(e)
ls(e)
names(e)
str(e$a)
str(as.list(e))
env_print(e)
```

### Scoping example

```{r}
find_var <- function(name, env) {
  if (env_has(env, name)) {
    env_get(env, name)
  } else {
    find_var(name, env_parent(env))
  }
}

e1 <- env()
e1$a <- 1
find_var("a", e1)
find_var("b", e1)
# Error: empty env has no parent
```

This approximates what `R` does to find a variable in an environment
```{r}
find_var <- function(name, env) {
  if (identical(env, empty_env())){
    stop("Object '", name, "' not found")
  } else if (env_has(env, name)) {
    env_get(env, name)
  } else {
    find_var(name, env_parent(env))
  }
}
find_var("a", e1)
find_var("b", e1)
# Error: Object 'b' not found
```

Let's do something a bit more useful:
instead of returning the variable, try returning the environment.
```{r, eval=TRUE}
find_env <- function(name, env) {
  if (identical(env, empty_env())){
    stop("Object '", name, "' not found")
  } else if (env_has(env, name)) {
    env
  } else {
    find_env(name, env_parent(env))
  }
}
find_env("a", e)
# Returns e1
find_env("find_env", e)
# Returns global environment
find_env("sd", e)
# Returns stats pkg env
```

The sequence of envs R looks in:
```{r, eval=TRUE}
search()
```

Does it take less time to find something in packages higher up in the search path?
Yes.
As you load more packages, it takes it a little bit longer to find packages.
But it's such a tiny differences it doesn't affect your code that much.

Back to the `sd` example:

```{r, eval=TRUE}
sd
find_env("var", environment(sd))
# in the stats package

my_sd
find_env("var", environment(my_sd))
# in the Global env
```

R version 3.0 introduced the concept of Namespaces to make sure packages play nicely with each other.

### Comparing environments
```{r}
get_env(ggplot2::geom_point)
get_env(dplyr::mutate)
get_env(MASS::select)
```
- What do these environments have in common?
- What's different?
- Tools to answer these questions: `env_print()`; `env_parent()`; `env_parents()`

```{r, eval=TRUE}
env_print(get_env(ggplot2::geom_point))
env_print(get_env(dplyr::mutate))
env_print(get_env(MASS::select))
```

`env_print` shows all the packages functions, including ones that aren't exported (can use triple colons `:::` to access them).

```{r, eval=TRUE}
env_parent(get_env(ggplot2::geom_point))
env_parent(get_env(dplyr::mutate))
env_parent(get_env(MASS::select))
```
```env_parent`: just get the immediate parent.

```{r, eval=TRUE}
env_parents(get_env(ggplot2::geom_point))
env_parents(get_env(dplyr::mutate))
env_parents(get_env(MASS::select))
```
`env_parents`: recursively gets parents

- What do these environments have in common?
  - They're all namespaces.
  - They share grandparents & great-grandparents.
- What's different?
  - They have different parents.

```{r, eval=TRUE}
lobstr::obj_addr(env_parent(get_env(ggplot2::geom_point))$grid.set)
lobstr::obj_addr(grid::grid.set)
```

When using functions from other packages, INCLUDING DEFAULT PACKAGES (but not `base`), need to call it explicitly or use the `importFrom` tag in the `Roxygen` comment.

Option A: 
```{r}
my_sd <- function(x) sqrt(stats::var(x))
```

Option B:
```{r}
#' @importFrom stats var
my_sd <- function(x) sqrt(var(x))
```

#### Exercise: importing default packages

- `create_package("ns")`
- `use_mit_license`
- `use_r("my_sd")`
- write the function & documentation
- run `document()` and `check()`
- fix the note

#### non-default packages

For non-default packages, also need to add them to the DESCRIPTION file.
```{r}
use_package("tibble")
use_package("dplyr")
```

#### The conflicted package

[r-lib/conflicted](https://github.com/r-lib/conflicted)

Makes all conflicts errors.
e.g. There's a filter in both base & dplyr; it will force you to pick one.

### Colon-Colon vs importFrom vs others

#### Colon-Colon `::`

```{r}
dplyr::filter()
```

This should be your default MO, because this makes it obvious that you're calling a function outside the package.

But there are downsides:

1. it's verbose. gets annoying to type.
1. you can't do this: `magrittr::%>%` (it's an infix operator).

#### importFrom

```{r}
#' @importFrom pkg fun1
```

1. For when you get annoyed with the verbosity of `::`.
1. For when you need to import the pipe or other infix operators.

#### import everything from a package

```{r}
#' @import pkg
```

Be careful about when you do this.

#### DON'T DO THIS

```{r}
`%<%` <- magrittr::`%<%`
```

Unless you really enjoy suffering. 
Hadley once spent six months debugging issues caused by this!

#### use_package_doc

`@importFrom` makes them available to everything in your package, not just that function.
A better practice is to make a place to put all of your `@importFrom` tags or other global roxygen commands.
Use `usethis::use_package_doc()`.

### NAMESPACE vs. DESCRIPTION

- `NAMESPACE`: about functions; managed completely by `roxygen2` (don't edit manually).
- `DESCRIPTION`: about the package; managed by `usethis` and _you_ (manually).

## Tidyverse in packages

- related article: [using ggplot2 in packages](https://ggplot2.tidyverse.org/dev/articles/ggplot2-in-packages.html)

### Warm-up

Turn this chunk of code into a package:
```{r}
library(ggplot2)
library(dplyr)
# cyl_plot()
ggplot(mtcars) + 
  geom_bar(aes(cyl)) + 
  coord_flip()
# cyl_sum()
mtcars %>% 
  group_by(cyl) %>% 
  summarise(n = n(), mpg = mean(mpg))
```

Question from the audience: what if you have a dependency listed in `DESCRIPTION` that you don't actually need? Is there a way to programmatically check for unneeded imports?
(Hadley probably knows. Maybe the `itdepends` package?)

### Tidy Eval / Data Masking

- **environment-variables** (programming); datasets - variables available in the (ggplot2) environment
  - `mtcars`
  - `starwars`
- **data-variables** (statistical); columns - variables available in the datasets
  - `cyl`
  - `mpg`
  - `homeworld`
  - `species`
  
The tidyverse blurs the distinction between whether something is an environment vs data variable. You only need to start thinking about this distincition when you start programming with the tidyverse.

Why use data masking? It makes your life easier as a data analyst.
  
```{r}
# tidyverse
starwars %>% filter(homeworld == "Naboo", species == "Human")

# base
starwars[starwars$homeworld == "Naboo" & starwars$species == "Human"]
```
(The base R version looks similar to Python pandas to me. I'm not a fan of how cumbersome that syntax is.)

But data masking makes it harder to program with the tidyverse.

### How to use tidy eval in your packages

- Preface data-variables inside your function with the `.data` pronoun from the `rlang` package, then refer to them like `.data$var`.
- Use the tidy eval operator `{{ var }}` ('embracing') to pass column names as variables to functions, OR pass it as a string and use `.data[[var]]`. Prefer the embracing solution, it's prettier!
- You can use the dots (`...`) arg to pass multiple vars, e.g.:
```{r}
group_summary <- function(df, x, ...) {
    df %>%
        group_by(...) %>%
        summarise(
            n = n(),
            min = min({{ x }}, na.rm = TRUE),
            max = max({{ x }}, na.rm = TRUE)
        )
}
```

(Question: how would you document the `...` arg in the roxygen comment?)

See [this article](https://ggplot2.tidyverse.org/dev/articles/ggplot2-in-packages.html#using-aes-and-vars-in-a-package-function) for more examples.

Hadley: the two curly braces are magic, they don't live anywhere. They are interpreted by tidyverse packages that use data masking (started about 6 months ago). Helps so programmers don't have to learn the theory underlying it (`enquo()` and `!!`); makes tidy eval more accessible.

### How to include data in your packages

- Code to prepare your raw dataset:
`usethis::use_data_raw("data")`: `data-raw/data.R`
- Also need to document the dataset:
`usethis::use_r("data")`: `R/data.R`

## Interface

- interface: outside of function
- implementation: inside of function

- The Tidyverse tries to have consistent interfaces across their function designs.
- Book in progress: [Tidyverse design guide](https://design.tidyverse.org/)
  - Probably at least 3 years away from completion.
  - When they discover a recurring pattern, they document it.
  
What are the properties of a function that define its interface (there are >= 9)?

- Name of the function
- Params / arguments / inputs
  - names & order
  - number of args
  - types 
  - default values / required vs optional
  - evaluation (regular, NSE, tidy eval)
- Output: what it returns
- Conditions
  - Errors
  - Warnings
  - Messages
- Side effects, e.g.
  - print
  - make a plot
  - disk I/O
  - change the random seed
- Environment that it's in?

### Case study: regular expressions / string manipulation

`stringr` vs. base R

Lots of inconsistencies in the interfaces for base R functions related to regex & string manipulation.

### Names

#### Functions should be verbs (usually)

| `base R` | `stringr` | Notes |
|------|---------|-------------|
| `grepl()` | `str_detect()` | returns logical vector |
| `grep()` | `str_which()` | returns location (integer vector) |
| `grep(value = TRUE)` | `str_subset()` | returns value (character vector) |
| `sub()` | `str_replace()` | |
| `gsub()` | `str_replace_all()` | |
| `strsplit()` | `str_split()` | |
| `regexpr()`  | `str_locate()` | returns location of pattern within string|

(More details in the [stringr docs](https://stringr.tidyverse.org/articles/from-base.html).)

Which functions are verbs in `ggplot2`? (`help(package=ggplot2)`)

- Most of them are nouns, not verbs.
- The layering system with `+` works well with nouns.
- Making them verbs would make them more verbose unnecessarily.
- Nouns work well in this case.

Another exception to the verb rule: when computing something, using the noun of the thing you're computing (e.g. `length`, `mean`) is pretty natural.

#### Prefixes & Suffixes

- Use prefixes to group together related functions. Helps you use autocomplete to jog your memory.
- Use suffices for variations on a theme.

##### When to use a suffix vs. an argument? 

e.g. it's `str_replace_all()`, not `str_replace(all=TRUE)`.

```{r, eval=TRUE}
x <- c('aba', 'aa', 'b')
stringr::str_locate(x, 'a')
```

```{r, eval=TRUE}
x <- c('aba', 'aa', 'b')
stringr::str_locate_all(x, 'a')
```

**An argument should not change the type of the output.**
It makes sense to have those as separate functions since they return different types.

However, the `str_to_`[`lower`/`upper`/`title`] functions could've been one function like `str_capitalize(to='lower')`.

**Avoid UK vs US spelling differences**:

`ggplot2::scale_color_grey()` uses American spelling of colo[u]r but the English spelling of gr[ae]y. Also `summarize` vs `summarise` is kind of annoying too.

#### Organizing function name components

Using dots `.` in function names is a bad idea.
```{r, eval=TRUE}
x <- structure(1:10, class='test')
t(x)
```

It called `t.test`! 

You should only ever use dots in the context of writing S3 methods.

Otherwise, just **be consistent**. Pick one style and stick with it!
Hadley likes snake_case, but camelCase is fine. 

"Any style is as good as any other style, except that my style is the best."

Follow a style guide to **be consistent**, e.g. [tidyverse style guide](https://style.tidyverse.org/).

Hadley's greatest victory: Google's R Style Guide is just the tidyverse style guide with some changes! 

#### Argument Names

- Be consistent.
- Use snake_case or camelCase to match your functions.
- Avoid dots.

#### Families of Arguments

Can you group arguments together based on their intent or purpose? Or how often they're used?

- data: primary input, positional & required (`data`, `x`, `text`)
- descriptors / identifiers: usually positional but could be optional/named (`pattern`, `start`, `stop`)
- details / modifiers: optional & named, change the behavior (`fixed`, `ignore.case`)

The most important arguments (the data) should come earlier. Also makes your function work with the pipe.

If you use `...` in your function, the details should come after `...`

For these functions, which args are required and which are optional?

| function | requried args | opitonal args |
|----------|---------------|---------------|
| `lm()`   | `formula` | `data`, `subset`, `weight`, ... |
| `sample()` | `x`     | `size`, `replace`, `prob`       |
| `diag()` | `nrow`        | `x`, `ncol`, `names` |
| `str_replace_all()` | `string`, `pattern`, `replacement`  | you can actually supply multiple replacements  |

As a general rule of thumb, don't do the above. Stick to:

- required = no default
- optional = has a default

To implement anything besides the default, you have to use `missing()`. Just don't do this. Exception: when you have a pair of mutually exclusive arguments (e.g. `read.table` can take a path to a file OR inline text; `forcats` function with `keep` and `drop`). 

#### Hidden Arguments

```{r, eval=TRUE}
options(stringsAsFactors = TRUE)
data.frame(x = "abc")  # x is fctr
options(stringsAsFactors = FALSE)
data.frame(x = "abc")  # x is chr
```

```{r, eval=TRUE}
# if you're in Turkey, tolower returns something different
tolower("I")
stringr::str_to_lower("I", locale='tr')
# this behavior caused ggplot2 to not work for Turkish people
```

```{r, eval=TRUE}
# not every alphabet organizes the letters in the same way
sort(c('a', 'o', 'å', 'ø'))
# stringr defaults to English
stringr::str_sort(c('a', 'o', 'å', 'ø'))
# in Swedish
stringr::str_sort(c('a', 'o', 'å', 'ø'), locale='se')
# related to Bioinf software that behaved differently depending on OS file sorting
```

Since `stringr` & `readr` have defaults for `locale` arg, the code will work the same way no matter where you're running it.

What do these functions have in common?

- `trimws()`
- `stringr::str_trunc()`
- `rank()`

Options with a list of possible values, powered by `match.arg()` (supports partial matching) OR `rlang::arg_match()` (no partial matching).

#### Triple dots `...` (aka ellipsis)

Generally used when you're passing on any number of arguments to another function.

Common general usage pattern:
```{r}
#' @param ... all other args passed onto group_by
count <- function(df, ...) {
  df %>%
    group_by(...) %>%
    summarize(n=n())
}
```

Major downside:
```{r, eval=TRUE}
sum(1,2,3)
mean(1,2,3)
weighted.mean(c(1,2,3), wt=c(1,0,0))  # actual arg name is `w`
```

Easy to accidentally swallow up additional positional or named arguments.

Package [`ellipsis`](https://github.com/r-lib/ellipsis) is designed to protect you from the pitfalls.

The development version of `dplyr` has new function `across()` to help expand variables that represent multiple data-variables for data masking semantics.
Will obviate the need for `summarise_at()`, etc. This will be a lot better in ~3 months time. Put `dev` after the doc url to get to the dev version of the docs.

### Type stability

How easy is it to interpret the type of the object that a function returns?

**What can you tell me about `x` and `y` knowing that this code works?**

`y <- sum(x)`

- `x`: numeric or logical vector/matrix/array of any length.
- `y`: numeric of length 1.

```{r, eval=TRUE}
typeof(sum(c(.Machine$integer.max)))
typeof(sum(c(1L, .Machine$integer.max)))
```


**What can you tell me about `x` and `y` knowing that this code does not error?**

`y <- mean(x)`

- `x`: absolutely nothing. `mean` throws a warning but not an error and returns `NA`.
- `y`: length 1, normally numeric but sometimes is `NA`.

Examples of dangerous things in base R:

- `df[, i]`: most of the time it'll be a data.frame, unless `i` is length 1, then it'll be a vector.
  - `df[i]`: but this always returns a data.frame.
- `sapply(x, mean)`: could return a `list` or `numeric vector`.

Keep your eye out for functions that sometimes return different types of objects. When writing your own functions, keep your types stable.

### Organizing

- Can you give the package a short, evocative name?  
- Err on the side of too many things in your package, rather than too few, so you don't have to remember which function is in which package.
  - But, it's hard to undo this. e.g. `purrrlyr`.
- That's why you can just `library(tidyverse)` and you don't have to care about where stuff is when doing analyses.
  - Not recommend to do this in your own package...
  - Normally you shouldn't use the `depends` field in `DESCRIPTION`, but could be useful for creating metapackages.

### Question time

Hadley's big goal: externalize the design principles so it scales. <https://design.tidyverse.org>

- Maybe have a badge to identify ecosystem of tidyverse-compatible packages.

Hadley's greatest shame: `dplyr::recode`:
```{r}
df %>% mutate(new = old)  # how almost everything does it
df %>% rename(new = old)
df %>% recode(old = new)  # recode flips new & old
```

## Object-oriented programming

- Base types - `typeof()`
- S3 - Simplest system of OOP. Longest history. Add attributes to a base object. Most important attribute `class`.
- S4 - Robust, but more complicated. Used by Bioconductor. Don't use it until there's a good book about it (according to Hadley, there isn't yet), unless you need it for Bioc.
- R6 - more like OOP in python. Powers reticulate & shiny. Avoid unless you really need it.

Five chapters in [`Advanced R`](https://adv-r.hadley.nz/).

### S3 Intro

Simplest OOP system that might work. (And it does!)

```{r, eval=TRUE}
df <- data.frame()
f <- factor()
mod <- lm(mpg ~ cyl, data = mtcars)
# S3
sloop::otype(df)
sloop::otype(f)
sloop::otype(mod)
sloop::otype(tibble::tibble())
sloop::otype(ggplot2::ggplot())
# base
sloop::otype(1:10)
sloop::otype(function(x) x)
```

All S3 objects are built on a base object. Use `typeof()` to find out.
```{r, eval=TRUE}
typeof(df)
typeof(f)
typeof(mod)
```

Find out the attributes an S3 object has:
```{r, eval=TRUE}
attributes(df)
```

### Why are S3 objects useful?

Example: the behavior of print depends on the object you give it
```{r, eval=TRUE}
x <- factor(1:10)
print(x)

class(x) <- "Date"
attributes(x)
x
```

- `print()` is a generic function. It looks to see what kind of class the function is, then looks for a specific implementation (method) for it.
- `method()` is a specific implementation of a generic function.
  - naming convention: `{generic}.{class}`
```{r, eval=TRUE}
sloop::ftype(print)
```

Use `sloop::s3_dispatch()` to find out the method used when a generic is called:
```{r, eval=TRUE}
x <- factor(1:10)
print(x)
sloop::s3_dispatch(print(x))
```
```{r, eval=TRUE}
y <- ordered(1:10)
print(y)
sloop::s3_dispatch(print(y))
```

Print the implementation of the method called by a generic
```{r}
sloop::s3_get_method(print.factor)
```

Find the implementation for the print functions for numerics & dates:
```{r, eval=TRUE}
n <- 10
class(n)
sloop::s3_dispatch(print(n))
```
```{r, eval=TRUE}
d <- Sys.Date()
sloop::s3_dispatch(print(d))
t <- Sys.time()
sloop::s3_dispatch(print(t))
```

Why override a generic? When you have a complicated object that you want to print nicely for your users.

### How to create an S3 class

#### Simplest way possible

```{r, eval=TRUE}
foo <- function() {
  x <- list()
  class(x) <- "foo"
  return(x)
}
my_foo <- foo()
my_foo
```

#### Best practices

[S3 chapter of Advanced R](https://adv-r.hadley.nz/s3.html)

Defining a print method for class `foo`:
```{r, eval=TRUE}
print.foo <- function(x, ...) {
  cat("Hello\n")
  invisible(x)
}
my_foo
```

**Question**: How to check that your new class name isn't already taken in base R?

### Defining a new generic function

Obviate the need for a ton of if clauses to make a function work on different object types.

```{r generic, eval=TRUE}
bizarro <- function(x) {
  UseMethod("bizarro")
}
str_reverse <- function(x) {
  purrr::map_chr(stringr::str_split(x, ""), 
    ~ stringr::str_flatten(rev(.x))  
  )
}
```

```{r methods, eval=TRUE}
# need to have same function signature as the generic
bizarro.character <- function(x) {
  str_reverse(x)
}
bizarro.numeric <- function(x) {
  x * -1
}
bizarro.logical <- function(x) {
  !x
}
bizarro.data.frame <- function(x) {
  colnames(x) <- bizarro(colnames(x))
  purrr::map(x, bizarro)
}
```

```{r, eval=TRUE}
bizarro(5)
bizarro(-275)
bizarro(c(TRUE, FALSE))
bizarro(mtcars)
```
